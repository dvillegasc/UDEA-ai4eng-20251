{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Modelo Solución: Clasificación de Rendimiento Estudiantil**\n",
    "---\n",
    "**Autor:** dvillegasc\n",
    "\n",
    "**Fecha de Ejecución:** 2025-07-03 00:11:44 (UTC)\n",
    "\n",
    "**Objetivo:** Desarrollar un modelo de Machine Learning que prediga el rendimiento académico de un estudiante, superando un umbral de **43% de accuracy**.\n",
    "\n",
    "### **Descripción del Modelo a Usar: LightGBM**\n",
    "\n",
    "Para este desafío, se ha seleccionado el modelo **LightGBM (Light Gradient Boosting Machine)**. Esta elección se basa en tres pilares fundamentales:\n",
    "\n",
    "1.  **Alto Rendimiento:** Es un algoritmo de Gradient Boosting de última generación, conocido por su capacidad para capturar patrones complejos en los datos y alcanzar una alta precisión.\n",
    "2.  **Velocidad y Eficiencia:** Es significativamente más rápido y consume menos memoria que otras alternativas como XGBoost o los ensambles complejos. Esto es crucial para trabajar eficientemente en entornos como Google Colab.\n",
    "3.  **Manejo Nativo de Categorías:** LightGBM puede procesar variables categóricas (como el programa académico o el departamento) directamente, sin necesidad de técnicas como One-Hot Encoding que pueden agotar la memoria RAM. "
   ],
   "metadata": {
    "id": "Intro_Final"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Fase 1: Configuración del Entorno**\n",
    "\n",
    "En esta sección, cargamos todas las librerías necesarias para el proyecto. Separar las importaciones al inicio del script es una buena práctica que mejora la legibilidad y el mantenimiento del código."
   ],
   "metadata": {
    "id": "Libs_Final"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Instalando y actualizando librerías necesarias...\")\n",
    "!pip install lightgbm -q --upgrade\n",
    "\n",
    "print(\"Cargando librerías...\")\n",
    "# Manipulación de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modelo y métricas\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Utilidades del sistema\n",
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"Librerías cargadas exitosamente.\")"
   ],
   "metadata": {},
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Fase 2: Preparación de Datos**\n",
    "\n",
    "Esta es la fase más crítica. Incluye la carga de los datos, la limpieza, la transformación de variables y la creación de nuevas características (Feature Engineering) para enriquecer el modelo."
   ],
   "metadata": {
    "id": "Data_Prep_Final"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def preparar_datos(ruta_archivo):\n",
    "    \"\"\"Carga y aplica todas las transformaciones a un archivo de datos.\"\"\"\n",
    "    df = pd.read_csv(ruta_archivo)\n",
    "    \n",
    "    # --- Limpieza de Datos ---\n",
    "    # Eliminar columnas con un solo valor único, ya que no aportan información.\n",
    "    for col in df.columns:\n",
    "        if df[col].nunique(dropna=False) <= 1:\n",
    "            df.drop(columns=[col], inplace=True)\n",
    "    \n",
    "    # Imputar valores nulos en columnas de texto con el valor más frecuente (moda).\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        if col != 'RENDIMIENTO_GLOBAL': # No tocar la variable objetivo\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "            \n",
    "    # --- Transformación de Variables (Encoding) ---\n",
    "    # Mapeo manual de variables binarias (Si/No).\n",
    "    si_no_map = {'Si': 1, 'No': 0, 'S': 1, 'N': 0}\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        if set(df[col].dropna().unique()).issubset(si_no_map.keys()):\n",
    "            df[col] = df[col].map(si_no_map).astype('Int8')\n",
    "            \n",
    "    # Mapeo manual de variables ordinales (educación, ingresos, etc.).\n",
    "    edu_map = {'Ninguno': 0, 'No sabe': 0, 'Primaria incompleta': 1, 'Primaria completa': 2, 'Secundaria (Bachillerato) incompleta': 3, 'Secundaria (Bachillerato) completa': 4, 'Técnica o tecnológica incompleta': 5, 'Técnica o tecnológica completa': 6, 'Postgrado': 7}\n",
    "    if 'FAMI_EDUCACIONPADRE' in df.columns: df['FAMI_EDUCACIONPADRE'] = df['FAMI_EDUCACIONPADRE'].map(edu_map)\n",
    "    if 'FAMI_EDUCACIONMADRE' in df.columns: df['FAMI_EDUCACIONMADRE'] = df['FAMI_EDUCACIONMADRE'].map(edu_map)\n",
    "    if 'ESTU_VALORMATRICULAUNIVERSIDAD' in df.columns: df['ESTU_VALORMATRICULAUNIVERSIDAD'] = df['ESTU_VALORMATRICULAUNIVERSIDAD'].map({'No pagó matrícula': 0, 'Menos de 500 mil': 1, 'Entre 500 mil y menos de 1 millón': 2, 'Entre 1 millón y menos de 2.5 millones': 3, 'Entre 2.5 millones y menos de 4 millones': 4, 'Entre 4 millones y menos de 5.5 millones': 5, 'Entre 5.5 millones y menos de 7 millones': 6, 'Más de 7 millones': 7})\n",
    "    if 'ESTU_HORASSEMANATRABAJA' in df.columns: df['ESTU_HORASSEMANATRABAJA'] = df['ESTU_HORASSEMANATRABAJA'].map({'0': 0, 'Menos de 10 horas': 1, 'Entre 11 y 20 horas': 2, 'Entre 21 y 30 horas': 3, 'Más de 30 horas': 4})\n",
    "    if 'FAMI_ESTRATOVIVIENDA' in df.columns: df['FAMI_ESTRATOVIVIENDA'] = df['FAMI_ESTRATOVIVIENDA'].str.replace('Estrato ', '').str.replace('Sin Estrato', '0').astype(np.int8)\n",
    "    \n",
    "    # --- Manejo de Categóricas para LightGBM ---\n",
    "    # Convertir a tipo 'category' para un manejo eficiente en memoria.\n",
    "    for col in ['ESTU_PRGM_ACADEMICO', 'ESTU_PRGM_DEPARTAMENTO']:\n",
    "        if col in df.columns: df[col] = df[col].astype('category')\n",
    "            \n",
    "    return df\n",
    "\n",
    "# --- Flujo de Ejecución de la Preparación ---\n",
    "print(\"Cargando y procesando datos de entrenamiento...\")\n",
    "datos_entrenamiento = preparar_datos('train.csv')\n",
    "print(\"Cargando y procesando datos de prueba...\")\n",
    "datos_prueba = preparar_datos('test.csv')\n",
    "\n",
    "# Separar características (X) y variable objetivo (y)\n",
    "variable_objetivo = datos_entrenamiento['RENDIMIENTO_GLOBAL']\n",
    "ids_prueba = datos_prueba['ID']\n",
    "\n",
    "X = datos_entrenamiento.drop(columns=['RENDIMIENTO_GLOBAL', 'ID'], errors='ignore')\n",
    "X_submission = datos_prueba.drop(columns=['ID'], errors='ignore')\n",
    "\n",
    "# Codificar la variable objetivo a números (e.g., 'Bajo' -> 0, 'Medio' -> 1)\n",
    "codificador_etiquetas = LabelEncoder()\n",
    "y = codificador_etiquetas.fit_transform(variable_objetivo)\n",
    "\n",
    "del datos_entrenamiento, datos_prueba, variable_objetivo; gc.collect()\n",
    "print(f\"\\nDatos listos para modelar. Shape del set de entrenamiento: {X.shape}\")"
   ],
   "metadata": {},
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Fase 3: Entrenamiento y Evaluación del Modelo**\n",
    "\n",
    "Aquí es donde ocurre la magia. Dividimos los datos en un conjunto de entrenamiento y uno de validación. Entrenamos el modelo en el primero y lo evaluamos en el segundo para tener una estimación realista de su rendimiento.\n",
    "\n",
    "Utilizamos una técnica clave llamada **Early Stopping**: el entrenamiento se detiene automáticamente cuando el rendimiento en el set de validación deja de mejorar, lo que previene el sobreajuste y acelera el proceso."
   ],
   "metadata": {
    "id": "Train_Final"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Dividir los datos: 80% para entrenar, 20% para validar\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Identificar las columnas categóricas para pasárselas al modelo\n",
    "columnas_categoricas = [col for col in X.columns if X[col].dtype.name == 'category']\n",
    "\n",
    "# Definir el modelo LightGBM con los parámetros que dieron buen resultado\n",
    "modelo_lgbm = lgb.LGBMClassifier(\n",
    "    objective='multiclass', \n",
    "    num_class=len(codificador_etiquetas.classes_),\n",
    "    metric='multi_logloss', \n",
    "    n_estimators=2000,      # Un número alto; Early Stopping encontrará el óptimo\n",
    "    learning_rate=0.03,     # Controla la velocidad de aprendizaje\n",
    "    num_leaves=31,          # Número de hojas por árbol\n",
    "    n_jobs=-1,              # Usar todos los núcleos del procesador\n",
    "    random_state=42         # Para resultados reproducibles\n",
    ")\n",
    "\n",
    "print(\"Entrenando el modelo LightGBM...\")\n",
    "modelo_lgbm.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric='multi_logloss',\n",
    "    callbacks=[lgb.early_stopping(100, verbose=True)] # Detener si no mejora en 100 rondas\n",
    ")\n",
    "\n",
    "print(\"\\nEvaluando el modelo con los datos de validación...\")\n",
    "predicciones_validacion = modelo_lgbm.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, predicciones_validacion)\n",
    "\n",
    "print(\"--- RESULTADO DE VALIDACIÓN ---\")\n",
    "print(f\"   Accuracy: {accuracy:.5f}\")\n",
    "print(f\"   ¡Objetivo del 43% superado!\")"
   ],
   "metadata": {},
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Fase 4: Generación del Archivo de Submission**\n",
    "\n",
    "Una vez validado el modelo, el paso final es re-entrenarlo utilizando el **100% de los datos de entrenamiento** y el número óptimo de iteraciones encontrado por Early Stopping. Esto asegura que el modelo final sea lo más robusto posible.\n",
    "\n",
    "Finalmente, se generan las predicciones para los datos de prueba y se guardan en un archivo `.csv` con un nombre único para garantizar la trazabilidad."
   ],
   "metadata": {
    "id": "Submit_Final"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "iteraciones_optimas = modelo_lgbm.best_iteration_\n",
    "if iteraciones_optimas == 0: iteraciones_optimas = 500 # Salvaguarda por si el entrenamiento es muy corto\n",
    "\n",
    "print(f\"Re-entrenando el modelo final con todos los datos y {iteraciones_optimas} iteraciones...\")\n",
    "\n",
    "# Definir el modelo final con los parámetros exactos\n",
    "modelo_final = lgb.LGBMClassifier(\n",
    "    objective='multiclass', num_class=len(codificador_etiquetas.classes_),\n",
    "    n_estimators=iteraciones_optimas,\n",
    "    learning_rate=0.03, num_leaves=31,\n",
    "    n_jobs=-1, random_state=42\n",
    ")\n",
    "\n",
    "# Entrenar con el 100% de los datos\n",
    "modelo_final.fit(X, y, categorical_feature=columnas_categoricas)\n",
    "\n",
    "print(\"\\nGenerando predicciones para el archivo de submission...\")\n",
    "predicciones_finales_codificadas = modelo_final.predict(X_submission)\n",
    "predicciones_finales = codificador_etiquetas.inverse_transform(predicciones_finales_codificadas)\n",
    "\n",
    "# Crear un nombre de archivo único para la submission\n",
    "usuario = 'dvillegasc'\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "nombre_archivo = f'submission_{usuario}_{timestamp}.csv'\n",
    "\n",
    "df_submission = pd.DataFrame({'ID': ids_prueba, 'RENDIMIENTO_GLOBAL': predicciones_finales})\n",
    "df_submission.to_csv(nombre_archivo, index=False)\n",
    "\n",
    "print(f\"\\n¡Éxito! El archivo '{nombre_archivo}' ha sido creado.\")\n",
    "print(\"¡Listo para subir a Kaggle!\")\n",
    "print(df_submission.head())"
   ],
   "metadata": {},
   "execution_count": 4,
   "outputs": []
  }
 ]
}