{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelo Solución: Clasificación de Rendimiento Estudiantil**\n",
        "---\n",
        "\n",
        "### **Modelo a Usar: LightGBM**\n",
        "\n",
        "Para este caso, se ha seleccionado el modelo **LightGBM (Light Gradient Boosting Machine)**. Conocido por su eficiencia y velocidad en el entrenamiento de modelos de aprendizaje automático basados en árboles de decisión"
      ],
      "metadata": {
        "id": "Intro_Final"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Fase 1: Configuración del Entorno**\n",
        "\n",
        "En esta sección, cargamos todas las librerías necesarias para el proyecto."
      ],
      "metadata": {
        "id": "Libs_Final"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm -q --upgrade\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import gc\n",
        "from datetime import datetime\n"
      ],
      "metadata": {
        "id": "z7tnqO0yodVE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Fase 2: Preparación de Datos**\n",
        "\n",
        "Carga de datos, limpieza, transformación de variables y creación de nuevas características (Feature Engineering) para mejorar el modelo."
      ],
      "metadata": {
        "id": "Data_Prep_Final"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preparar_datos(ruta_archivo):\n",
        "    \"\"\"Carga y aplica todas las transformaciones a un archivo de datos.\"\"\"\n",
        "    df = pd.read_csv(ruta_archivo)\n",
        "\n",
        "    # --- Limpieza de Datos ---\n",
        "    # Eliminar columnas con un solo valor único, ya que no aportan información.\n",
        "    for col in df.columns:\n",
        "        if df[col].nunique(dropna=False) <= 1:\n",
        "            df.drop(columns=[col], inplace=True)\n",
        "\n",
        "    # Imputar valores nulos en columnas de texto con el valor más frecuente (moda).\n",
        "    for col in df.select_dtypes(include=['object']).columns:\n",
        "        if col != 'RENDIMIENTO_GLOBAL': # No tocar la variable objetivo\n",
        "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
        "\n",
        "    # --- Transformación de Variables (Encoding) ---\n",
        "    # Mapeo de variables binarias (Si/No).\n",
        "    si_no_map = {'Si': 1, 'No': 0, 'S': 1, 'N': 0}\n",
        "    for col in df.select_dtypes(include=['object']).columns:\n",
        "        if set(df[col].dropna().unique()).issubset(si_no_map.keys()):\n",
        "            df[col] = df[col].map(si_no_map).astype('Int8')\n",
        "\n",
        "    # Mapeo de variables ordinales (educación, ingresos, etc.).\n",
        "    edu_map = {'Ninguno': 0, 'No sabe': 0, 'Primaria incompleta': 1, 'Primaria completa': 2, 'Secundaria (Bachillerato) incompleta': 3, 'Secundaria (Bachillerato) completa': 4, 'Técnica o tecnológica incompleta': 5, 'Técnica o tecnológica completa': 6, 'Postgrado': 7}\n",
        "    if 'FAMI_EDUCACIONPADRE' in df.columns: df['FAMI_EDUCACIONPADRE'] = df['FAMI_EDUCACIONPADRE'].map(edu_map)\n",
        "    if 'FAMI_EDUCACIONMADRE' in df.columns: df['FAMI_EDUCACIONMADRE'] = df['FAMI_EDUCACIONMADRE'].map(edu_map)\n",
        "    if 'ESTU_VALORMATRICULAUNIVERSIDAD' in df.columns: df['ESTU_VALORMATRICULAUNIVERSIDAD'] = df['ESTU_VALORMATRICULAUNIVERSIDAD'].map({'No pagó matrícula': 0, 'Menos de 500 mil': 1, 'Entre 500 mil y menos de 1 millón': 2, 'Entre 1 millón y menos de 2.5 millones': 3, 'Entre 2.5 millones y menos de 4 millones': 4, 'Entre 4 millones y menos de 5.5 millones': 5, 'Entre 5.5 millones y menos de 7 millones': 6, 'Más de 7 millones': 7})\n",
        "    if 'ESTU_HORASSEMANATRABAJA' in df.columns: df['ESTU_HORASSEMANATRABAJA'] = df['ESTU_HORASSEMANATRABAJA'].map({'0': 0, 'Menos de 10 horas': 1, 'Entre 11 y 20 horas': 2, 'Entre 21 y 30 horas': 3, 'Más de 30 horas': 4})\n",
        "    if 'FAMI_ESTRATOVIVIENDA' in df.columns: df['FAMI_ESTRATOVIVIENDA'] = df['FAMI_ESTRATOVIVIENDA'].str.replace('Estrato ', '').str.replace('Sin Estrato', '0').astype(np.int8)\n",
        "\n",
        "    # --- Manejo de Categóricas para LightGBM ---\n",
        "    # Convertir a tipo 'category' para un manejo eficiente en memoria.\n",
        "    for col in ['ESTU_PRGM_ACADEMICO', 'ESTU_PRGM_DEPARTAMENTO']:\n",
        "        if col in df.columns: df[col] = df[col].astype('category')\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "WjJ0YAgSodVI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Ejecución de la Preparación ---\n",
        "datos_entrenamiento = preparar_datos('train.csv')\n",
        "datos_prueba = preparar_datos('test.csv')\n",
        "\n",
        "# Separar características (X) y variable objetivo (y)\n",
        "variable_objetivo = datos_entrenamiento['RENDIMIENTO_GLOBAL']\n",
        "ids_prueba = datos_prueba['ID']\n",
        "\n",
        "X = datos_entrenamiento.drop(columns=['RENDIMIENTO_GLOBAL', 'ID'], errors='ignore')\n",
        "X_submission = datos_prueba.drop(columns=['ID'], errors='ignore')\n",
        "\n",
        "# Codificar la variable objetivo a números\n",
        "codificador_etiquetas = LabelEncoder()\n",
        "y = codificador_etiquetas.fit_transform(variable_objetivo)\n",
        "\n",
        "del datos_entrenamiento, datos_prueba, variable_objetivo; gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otNVxIO3sDHJ",
        "outputId": "eb6c20a5-8633-417f-ca3c-c60fc27e560f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3-4043954574.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
            "/tmp/ipython-input-3-4043954574.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Fase 3: Entrenamiento y Evaluación del Modelo**\n",
        "\n",
        "Dividimos los datos en un conjunto de entrenamiento y uno de validación. Entrenamos el modelo en el primero y lo evaluamos en el segundo para tener una estimación realista de su rendimiento.\n",
        "\n",
        "Utilizamos una técnica clave llamada **Early Stopping**: el entrenamiento se detiene automáticamente cuando el rendimiento en el set de validación deja de mejorar, lo que previene el sobreajuste y acelera el proceso."
      ],
      "metadata": {
        "id": "Train_Final"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir los datos: 80% para entrenar, 20% para validar\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Identificar las columnas categóricas para pasárselas al modelo\n",
        "columnas_categoricas = [col for col in X.columns if X[col].dtype.name == 'category']\n",
        "\n",
        "# Definir el modelo LightGBM con los parámetros\n",
        "modelo_lgbm = lgb.LGBMClassifier(\n",
        "    objective='multiclass',\n",
        "    num_class=len(codificador_etiquetas.classes_),\n",
        "    metric='multi_logloss',\n",
        "    n_estimators=2000,      # Un número alto; Early Stopping encontrará el óptimo\n",
        "    learning_rate=0.03,     # Controla la velocidad de aprendizaje\n",
        "    num_leaves=31,          # Número de hojas por árbol\n",
        "    n_jobs=-1,              # Usar todos los núcleos del procesador\n",
        "    random_state=42         # Para resultados reproducibles\n",
        ")\n",
        "\n",
        "modelo_lgbm.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    eval_metric='multi_logloss',\n",
        "    callbacks=[lgb.early_stopping(100, verbose=True)] # Detener si no mejora en 100 rondas\n",
        ")\n",
        "\n",
        "predicciones_validacion = modelo_lgbm.predict(X_val)\n",
        "accuracy = accuracy_score(y_val, predicciones_validacion)\n",
        "\n",
        "print(\"--- RESULTADO ---\")\n",
        "print(f\"   Accuracy: {accuracy:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-EMDzSmodVJ",
        "outputId": "a49f471e-e1cc-4ad2-be53-e20472d70fea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053758 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1620\n",
            "[LightGBM] [Info] Number of data points in the train set: 554000, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score -1.371993\n",
            "[LightGBM] [Info] Start training from score -1.387089\n",
            "[LightGBM] [Info] Start training from score -1.395033\n",
            "[LightGBM] [Info] Start training from score -1.391216\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[469]\tvalid_0's multi_logloss: 1.19242\n",
            "--- RESULTADO ---\n",
            "   Accuracy: 0.43903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Fase 4: Generación del Archivo de Submission**\n",
        "\n",
        "Una vez validado el modelo, el paso final es re-entrenarlo utilizando el **100% de los datos de entrenamiento** y el número óptimo de iteraciones encontrado por Early Stopping. Esto asegura que el modelo final sea lo más robusto posible.\n",
        "\n",
        "Finalmente, se generan las predicciones para los datos de prueba y se guardan en un archivo `.csv` con un nombre único para garantizar la trazabilidad."
      ],
      "metadata": {
        "id": "Submit_Final"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iteraciones_optimas = modelo_lgbm.best_iteration_\n",
        "if iteraciones_optimas == 0: iteraciones_optimas = 500 # Salvaguarda por si el entrenamiento es muy corto\n",
        "\n",
        "# Definir el modelo final con los parámetros exactos\n",
        "modelo_final = lgb.LGBMClassifier(\n",
        "    objective='multiclass', num_class=len(codificador_etiquetas.classes_),\n",
        "    n_estimators=iteraciones_optimas,\n",
        "    learning_rate=0.03, num_leaves=31,\n",
        "    n_jobs=-1, random_state=42\n",
        ")\n",
        "\n",
        "# Entrenar con el 100% de los datos\n",
        "modelo_final.fit(X, y, categorical_feature=columnas_categoricas)\n",
        "\n",
        "print(\"\\nGenerando predicciones para el archivo de submission...\")\n",
        "predicciones_finales_codificadas = modelo_final.predict(X_submission)\n",
        "predicciones_finales = codificador_etiquetas.inverse_transform(predicciones_finales_codificadas)\n",
        "\n",
        "# Nombre de archivo para la submission\n",
        "nombre_archivo = f'submission_final.csv'\n",
        "\n",
        "df_submission = pd.DataFrame({'ID': ids_prueba, 'RENDIMIENTO_GLOBAL': predicciones_finales})\n",
        "df_submission.to_csv(nombre_archivo, index=False)\n",
        "\n",
        "print(f\"\\nEl archivo '{nombre_archivo}' ha sido creado.\")\n",
        "print(df_submission.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5oRmhioodVK",
        "outputId": "f62f7897-85dc-4bab-938f-07fa954c71da"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.334518 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1615\n",
            "[LightGBM] [Info] Number of data points in the train set: 692500, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score -1.371991\n",
            "[LightGBM] [Info] Start training from score -1.387092\n",
            "[LightGBM] [Info] Start training from score -1.395031\n",
            "[LightGBM] [Info] Start training from score -1.391216\n",
            "\n",
            "Generando predicciones para el archivo de submission...\n",
            "\n",
            "El archivo 'submission_final.csv' ha sido creado.\n",
            "       ID RENDIMIENTO_GLOBAL\n",
            "0  550236               bajo\n",
            "1   98545         medio-alto\n",
            "2  499179               alto\n",
            "3  782980               bajo\n",
            "4  785185               bajo\n"
          ]
        }
      ]
    }
  ]
}